# Metric Selection Worksheet

## Team Information
- **Team Name**: ________________
- **Team Size**: ________________
- **Primary Function**: ________________ (Development, QA, DevOps, Product, etc.)
- **Current AI Tools in Use**: ________________
- **AI Tools Being Implemented**: ________________

## Measurement Objectives

### Primary Goals (select top 3)
- [ ] Increase development productivity
- [ ] Improve code/product quality
- [ ] Enhance team collaboration
- [ ] Accelerate innovation and learning
- [ ] Reduce operational overhead
- [ ] Improve customer satisfaction
- [ ] Decrease time-to-market
- [ ] Other: ________________

### Success Criteria
What would "success" look like in 6 months?
- ________________
- ________________
- ________________

## Metric Selection

### Productivity Metrics (select 2-3)
- [ ] **Story Points per Sprint** - Velocity tracking
  - Current baseline: ______ points/sprint
  - Target improvement: ______ % increase
- [ ] **Code Review Turnaround** - PR creation to merge time
  - Current baseline: ______ hours average
  - Target improvement: ______ % decrease
- [ ] **Feature Delivery Time** - End-to-end feature completion
  - Current baseline: ______ days average
  - Target improvement: ______ % decrease
- [ ] **Lines of Code per Hour** - With/without AI assistance
  - Current baseline: ______ LOC/hour
  - Target improvement: ______ % increase
- [ ] **Documentation Creation Speed** - Time to create docs
  - Current baseline: ______ hours per doc
  - Target improvement: ______ % decrease

### Quality Metrics (select 1-2)
- [ ] **Bug Density** - Defects per 1000 lines of code
  - Current baseline: ______ bugs/1000 LOC
  - Target improvement: ______ % decrease
- [ ] **First-Time-Right Rate** - Work completed without rework
  - Current baseline: ______ % first-time right
  - Target improvement: ______ % increase
- [ ] **Code Coverage** - Automated test coverage
  - Current baseline: ______ % coverage
  - Target improvement: ______ % increase
- [ ] **Customer Satisfaction (CSAT)** - Customer feedback scores
  - Current baseline: ______ /10 average
  - Target improvement: ______ point increase

### Collaboration Metrics (select 1-2)
- [ ] **Meeting Efficiency** - Productive vs total meeting time
  - Current baseline: ______ % efficient time
  - Target improvement: ______ % increase
- [ ] **Knowledge Sharing Rate** - Documentation updates/contributions
  - Current baseline: ______ updates/month
  - Target improvement: ______ % increase
- [ ] **Cross-team Collaboration** - Inter-team communications
  - Current baseline: ______ interactions/week
  - Target improvement: ______ % increase
- [ ] **Decision Velocity** - Time from discussion to decision
  - Current baseline: ______ days average
  - Target improvement: ______ % decrease

### Innovation Metrics (select 1-2)
- [ ] **Ideas Implemented** - Suggestions that become features
  - Current baseline: ______ ideas/month
  - Target improvement: ______ % increase
- [ ] **Prototype Development Speed** - Time to create prototypes
  - Current baseline: ______ days average
  - Target improvement: ______ % decrease
- [ ] **Skill Acquisition Rate** - New skills learned per quarter
  - Current baseline: ______ skills/person/quarter
  - Target improvement: ______ % increase
- [ ] **Learning Application** - Skills applied to projects
  - Current baseline: ______ % application rate
  - Target improvement: ______ % increase

## AI-Specific Metrics (select 2-3)
- [ ] **AI Tool Adoption Rate** - % of team actively using AI tools
  - Target: ______ % adoption within ______ weeks
- [ ] **AI Suggestion Acceptance** - % of AI suggestions accepted
  - Target: ______ % acceptance rate
- [ ] **AI-Human Collaboration Time** - Time in AI-assisted work
  - Target: ______ % of work time AI-assisted
- [ ] **AI-Attributed Productivity Gains** - Performance improvements from AI
  - Target: ______ % productivity gain attributable to AI

## Data Sources and Collection Methods

### Automated Data Sources Available
- [ ] Jira/Azure DevOps - Sprint and task data
- [ ] GitHub/GitLab - Code repository metrics
- [ ] CI/CD Tools - Build and deployment data
- [ ] Slack/Teams - Communication analytics
- [ ] Time Tracking Tools - Detailed time data
- [ ] Customer Support - Ticket and satisfaction data
- [ ] Other: ________________

### Survey and Manual Collection Plan
- **Weekly Pulse Survey**: ______ questions, ______ minutes
- **Monthly Team Survey**: ______ questions, ______ minutes
- **Quarterly Interviews**: ______ people, ______ minutes each
- **Focus Groups**: ______ sessions per quarter, ______ participants each

## Implementation Timeline

### Week 1-2: Setup
- [ ] Stakeholder alignment
- [ ] Tool selection and procurement
- [ ] Data collection infrastructure setup
- [ ] Baseline measurement planning

### Week 3-6: Baseline Collection
- [ ] Collect ______ weeks of baseline data
- [ ] Conduct baseline team survey
- [ ] Document current processes
- [ ] Analyze baseline performance

### Week 7-12: AI Tool Implementation
- [ ] Pilot rollout (______ % of team)
- [ ] Full rollout (100% of team)
- [ ] Intensive measurement and tracking
- [ ] Weekly feedback collection

### Week 13+: Analysis and Optimization
- [ ] Monthly performance reports
- [ ] Quarterly comprehensive analysis
- [ ] Continuous improvement implementation
- [ ] Stakeholder communication

## Resource Requirements

### Personnel Time Commitment
- **Project Lead**: ______ hours/week
- **Data Analyst**: ______ hours/week
- **Team Members**: ______ hours/week each (for surveys/feedback)

### Budget Requirements
- **Tools and Platforms**: $______ /month
- **Setup Costs**: $______ one-time
- **Ongoing Analysis**: $______ /quarter

### Technology Requirements
- [ ] Dashboard/Analytics Platform: ________________
- [ ] Survey Tool: ________________
- [ ] Data Storage: ________________
- [ ] Integration Tools: ________________

## Risk Assessment

### Potential Challenges
- [ ] Data quality and consistency issues
- [ ] Team resistance to measurement
- [ ] Difficulty attributing improvements to AI
- [ ] Information overload from too many metrics
- [ ] Other: ________________

### Mitigation Strategies
- ________________
- ________________
- ________________

## Success Metrics for the Measurement Process Itself

- [ ] Data collection accuracy > ______ %
- [ ] Survey response rate > ______ %
- [ ] Dashboard update frequency: ______ 
- [ ] Stakeholder engagement: ______ meetings/reports per month
- [ ] Time from data collection to insights: < ______ days

## Approval and Sign-off

### Stakeholders
- **Team Lead**: ________________ Date: ________
- **Product Manager**: ________________ Date: ________
- **Engineering Manager**: ________________ Date: ________
- **Data/Analytics Lead**: ________________ Date: ________

### Next Steps
1. [ ] Complete team readiness assessment
2. [ ] Set up data collection infrastructure  
3. [ ] Begin baseline measurement period
4. [ ] Schedule regular review meetings
5. [ ] Create detailed implementation timeline

---

**Notes:**
Use this worksheet to guide your metric selection process. Focus on metrics that:
1. Align with your primary objectives
2. Can be reliably measured with available data sources
3. Will provide actionable insights
4. Balance leading and lagging indicators
5. Consider both quantitative and qualitative aspects